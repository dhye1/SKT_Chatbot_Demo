###################### ê°ì • ë° ìš°ìš¸ ì¦ìƒ ì˜ˆì¸¡ page ###############################
import os
import requests
import subprocess
from dotenv import load_dotenv
import streamlit as st
from audio_recorder_streamlit import audio_recorder
from streamlit_float import *
from src.utils import Utils
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import shap
import transformers
import streamlit.components.v1 as components

load_dotenv()
api_key = os.getenv("openai_api_key")
utils = Utils(api_key=api_key)

# ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ ì„¤ì •
IMAGE_PATHS = {
    "anger": "img/anger.png",
    "excited": "img/excited.png",
    "frustrated": "img/frustrated2.png",
    "happy": "img/happy.png",
    "neutral": "img/neutral.png",
    "sadness": "img/sadness2.png",
}

# Flask ê¸°ë°˜ ë©€í‹°ëª¨ë‹¬ ëª¨ë¸ì´ ëŒì•„ê°€ëŠ” ì„œë²„ì˜ ì£¼ì†Œì™€ í¬íŠ¸ ì„¤ì •
FLASK_API_URL = "http://localhost:5000/predict"

# BERT ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì € ë¡œë“œ (ê°ì • ì˜ˆì¸¡ìš©)
tokenizer = transformers.AutoTokenizer.from_pretrained("nateraw/bert-base-uncased-emotion", use_fast=True)
model = transformers.AutoModelForSequenceClassification.from_pretrained("nateraw/bert-base-uncased-emotion").cuda()

# ì˜ˆì¸¡ì„ ìœ„í•œ íŒŒì´í”„ë¼ì¸ ìƒì„±
pred = transformers.pipeline(
    "text-classification",
    model=model,
    tokenizer=tokenizer,
    device=0,
    return_all_scores=True,
)

# Reset session state for messages when entering this page
def reset_session_state() -> None:
    if "messages" not in st.session_state:
        st.session_state["messages"] = []
    if "audio_data" not in st.session_state:
        st.session_state["audio_data"] = b""  # ì˜¤ë””ì˜¤ ë°ì´í„°ë¥¼ ì €ì¥í•  ë³€ìˆ˜
    if "full_transcript" not in st.session_state:
        st.session_state["full_transcript"] = ""  # ì „ì²´ í…ìŠ¤íŠ¸ë¥¼ ì €ì¥í•  ë³€ìˆ˜
    st.session_state["prediction_complete"] = False  # ì˜ˆì¸¡ ì™„ë£Œ í”Œë˜ê·¸ ì´ˆê¸°í™”
    st.session_state["final_message"] = ""  # ìµœì¢… ë©”ì‹œì§€ ì´ˆê¸°í™”
    st.session_state["displayed_messages"] = []  # ì´ë¯¸ í‘œì‹œëœ ë©”ì‹œì§€ë¥¼ ì¶”ì 

reset_session_state()
float_init()

st.write("### Emotion Recognition & Depression Detection ğŸ©º")
st.info("ë§ˆì´í¬ ë²„íŠ¼ì„ ëˆ„ë¥´ê³  ë§ˆì´í¬ì— ë§í•´ì£¼ì„¸ìš”.")

questions = [
    "How have you been over the past few days? Have you felt any particular feelings recently?",
    "Thank you for sharing, it sounds like this has been meaningful for you. Have there been any specific events or situations that have affected your mood lately?",
    "When you feel this way, what kinds of thoughts usually come to mind?",
    "Have you been experiencing any changes in appetite, sleep, or energy levels recently?",
    "Would you say these feelings have been consistent, or do they come and go throughout the day?"
]

with st.chat_message("assistant"):
    st.write(questions[0])

def initialize_session_state() -> None:
    if "messages" not in st.session_state:
        st.session_state.messages = [{"role": "assistant", "content": questions[0]}]
    if "question_idx" not in st.session_state:
        st.session_state.question_idx = 0

initialize_session_state()

# ì²« ë²ˆì§¸ ì§ˆë¬¸ì„ ê°•ì œë¡œ í™”ë©´ì— ì¶œë ¥
if st.session_state.messages and not st.session_state.displayed_messages:
    with st.chat_message("assistant"):
        st.write(st.session_state.messages[0]["content"])
    st.session_state.displayed_messages.append(st.session_state.messages[0])

# ì´ì „ ëŒ€í™” ë‚´ìš© ì¶œë ¥ (ì´ë¯¸ í‘œì‹œëœ ë©”ì‹œì§€ë§Œ ì¶œë ¥)
for message in st.session_state.messages[1:]:
    if message not in st.session_state.displayed_messages:
        with st.chat_message(message["role"]):
            st.write(message["content"])
        st.session_state.displayed_messages.append(message)

footer_container = st.container()
with footer_container:
    col1, col2 = st.columns([1, 1])
    with col1:
        st.markdown("<p style='font-size: 24px; font-weight: bold; margin-left: 170px;'>Click to record</p>", unsafe_allow_html=True)
    with col2:
        audio_bytes = audio_recorder(icon_name="microphone", icon_size="3x", neutral_color="#000000", recording_color="#fc0000", text="")

# ìŒì„± ë°ì´í„° ì²˜ë¦¬
if audio_bytes:
    with st.spinner("ìŒì„± ì¸ì‹ ì¤‘..."):
        try:
            # webm íŒŒì¼ë¡œ ì €ì¥
            webm_file_path = "temp_audio.webm"
            with open(webm_file_path, "wb") as f:
                f.write(audio_bytes)

            # ffmpegë¥¼ ì‚¬ìš©í•´ webm íŒŒì¼ì„ wavë¡œ ë³€í™˜
            wav_file_path = "temp_audio.wav"
            ffmpeg_command = ["ffmpeg", "-y", "-i", webm_file_path, wav_file_path]
            subprocess.run(ffmpeg_command, check=True)

            transcript = utils.stt(wav_file_path)
            if transcript:
                # ìœ ì € ë©”ì‹œì§€ë¥¼ ì„¸ì…˜ì— ì¶”ê°€í•˜ê³  full_transcriptì— ì¤„ë°”ê¿ˆìœ¼ë¡œ ì¶”ê°€
                st.session_state.messages.append({"role": "user", "content": transcript})
                st.session_state.full_transcript += f"{transcript}\n"  # 'User:' ìƒëµí•˜ê³  í•œ ì¤„ì”© ì¶”ê°€
                with st.chat_message("user"):
                    st.write(transcript)

            # ì§ˆë¬¸ ì¶”ê°€
            question_idx = st.session_state.question_idx
            if question_idx < len(questions) - 1:
                question_idx += 1
                st.session_state.question_idx = question_idx
                next_question = questions[question_idx]

                # Assistant ë©”ì‹œì§€ë¥¼ ì„¸ì…˜ì— ì¶”ê°€ (full_transcriptì—ëŠ” ì¶”ê°€í•˜ì§€ ì•ŠìŒ)
                st.session_state.messages.append({"role": "assistant", "content": next_question})
                with st.chat_message("assistant"):
                    st.write(next_question)
            else:
                with st.spinner("ì „ì²´ ëŒ€í™” ì„¸ì…˜ì— ëŒ€í•œ ê°ì • ë° ìš°ìš¸ì¦ ì˜ˆì¸¡ ì¤‘..."):
                    with open(wav_file_path, "rb") as audio_file:
                        files = {'audio_file': audio_file}
                        data = {'text': st.session_state.full_transcript}  # User ë©”ì‹œì§€ë§Œ í¬í•¨ëœ full_transcript ì „ì†¡
                        try:
                            response = requests.post(FLASK_API_URL, files=files, data=data, timeout=30)
                            if response.status_code == 200:
                                response_data = response.json()
                                emotion_prediction = response_data.get("emotion_prediction", "ì˜ˆì¸¡ ì‹¤íŒ¨")
                                depression_prediction = response_data.get("depression_prediction", "ì˜ˆì¸¡ ì‹¤íŒ¨")
                                symptom_weights = response_data.get("symptom_weights", {})

                                # ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥
                                st.session_state["predicted_emotion"] = emotion_prediction
                                st.session_state["depression_symptoms"] = symptom_weights
                                st.session_state["depression_status"] = depression_prediction

                                # ì˜ˆì¸¡ ê²°ê³¼ ë©”ì‹œì§€
                                final_message = f"Your current emotion is **'{emotion_prediction}'**."
                                st.session_state["final_message"] = final_message
                                st.session_state.messages.append({"role": "assistant", "content": final_message})

                                # ê°ì • ì˜ˆì¸¡ ê²°ê³¼ì— ë”°ë¥¸ ì´ë¯¸ì§€ ì¶œë ¥
                                # st.write("### Overall predictions")
                                image_path = IMAGE_PATHS.get(emotion_prediction)
                                if image_path and os.path.exists(image_path):
                                    st.image(image_path, caption=f"Emotion: {emotion_prediction.capitalize()}", use_column_width=True)
                                else:
                                    st.write(f"Image for {emotion_prediction} not found.")

                                # ì¤‘ë³µ ì œê±° ë° í•œ ì¤„ì”© ë„ì›Œì„œ ì €ì¥í•œ user_transcript ìƒì„±
                                user_messages = [message["content"] for message in st.session_state.messages if message["role"] == "user"]

                                # ì¤‘ë³µì„ ì œê±°í•˜ê³  ì¤„ë°”ê¿ˆìœ¼ë¡œ ì—°ê²°
                                unique_user_messages = []
                                for msg in user_messages:
                                    if msg not in unique_user_messages:
                                        unique_user_messages.append(msg)

                                user_transcript = "\n".join(unique_user_messages)

                                # SHAP í•´ì„ ìƒì„± ë° ì‹œê°í™” ê²°ê³¼ í‘œì‹œ (HTML ì„ë² ë“œ)
                                explainer = shap.Explainer(pred)
                                shap_values = explainer([user_transcript])
                                shap_html = shap.plots.text(shap_values[0], display=False)
                                components.html(shap_html, height=200)


                                st.session_state["prediction_complete"] = True
                            else:
                                st.error(f"ì˜ˆì¸¡ ì‹¤íŒ¨ - ìƒíƒœ ì½”ë“œ: {response.status_code}, ë‚´ìš©: {response.text}")

                        except requests.exceptions.Timeout:
                            st.error("ì„œë²„ ì‘ë‹µ ì‹œê°„ì´ ì´ˆê³¼ë˜ì—ˆìŠµë‹ˆë‹¤.")
                        except requests.exceptions.RequestException as e:
                            st.error(f"ìš”ì²­ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

            os.remove(webm_file_path)
            os.remove(wav_file_path)

        except Exception as e:
            st.error(f"ì˜¤ë¥˜ ë°œìƒ: {str(e)}")




# íˆíŠ¸ë§µ ì‹œê°í™” í•¨ìˆ˜
def plot_symptom_heatmap(symptom_weights):
    symptoms = list(symptom_weights.keys())
    weights = list(symptom_weights.values())
    data = pd.DataFrame(weights, index=symptoms, columns=["Weight"])

    plt.figure(figsize=(3, 2))
    sns.heatmap(
        data,
        annot=True,
        cmap="PuBuGn",  # ë…¸ë€ìƒ‰ì—ì„œ ë¹¨ê°„ìƒ‰ìœ¼ë¡œì˜ ê·¸ë¼ë°ì´ì…˜ ì»¬ëŸ¬ë§µ
        cbar=True,
        linewidths=0.5,
        fmt=".4f",
        vmin=0,
        vmax=1  # ìµœëŒ€ ê°’ì„ 1ë¡œ ì„¤ì •í•˜ì—¬ ê°•í•œ ìƒ‰ ëŒ€ë¹„ ì ìš©
    )
    st.pyplot(plt)


# ì˜ˆì¸¡ ì™„ë£Œ ì‹œ ìµœì¢… ë©”ì‹œì§€ì™€ íˆíŠ¸ë§µì„ ì¶œë ¥
if st.session_state.get("prediction_complete"):
    # ì´ë¯¸ ì¶œë ¥ëœ ë©”ì‹œì§€ì™€ ì¤‘ë³µë˜ì§€ ì•Šë„ë¡ ê´€ë¦¬
    for message in st.session_state.messages:
        if message not in st.session_state.displayed_messages:
            with st.chat_message(message["role"]):
                st.write(message["content"])
            st.session_state.displayed_messages.append(message)

    # ìµœì¢… ë©”ì‹œì§€ê°€ ì´ë¯¸ ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸ì— ìˆëŠ”ì§€ í™•ì¸ í›„ ì¶”ê°€
    final_message = f"Your current emotion is **'{st.session_state['predicted_emotion']}'**."
    if {"role": "assistant", "content": final_message} not in st.session_state.messages:
        st.session_state.messages.append({"role": "assistant", "content": final_message})

    # # ì „ì²´ ëŒ€í™” ë‚´ìš© (full_transcript) ì¶œë ¥
    # st.write("### Full Transcript")
    # st.write(st.session_state["full_transcript"])  # full_transcript ì¶œë ¥

    # ê°ì • ì˜ˆì¸¡ ê²°ê³¼ ì¶œë ¥
    st.write("### Prediction Results")
    st.write(f"**Emotion Prediction**: {st.session_state['predicted_emotion']}")

    # ìš°ìš¸ì¦ ì—¬ë¶€ ì¶œë ¥ ('non'ì´ë©´ No, ê·¸ ì™¸ì—ëŠ” Yes)
    depression_status = "No" if st.session_state.get("depression_status") == "non" else "Yes"
    st.write(f"**Depression Status**: {depression_status}")

    # íˆíŠ¸ë§µ ì¶œë ¥
    symptom_weights = st.session_state["depression_symptoms"]
    plot_symptom_heatmap(symptom_weights)



footer_container.float("bottom: 0rem;")








